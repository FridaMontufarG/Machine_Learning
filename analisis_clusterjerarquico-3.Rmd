---
title: "Analisis de clusters jerarquicos y Kmedias"
author: "Equipo 5"
date: "3/10/2021"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

### integrantes:

Tomás Rodriguez Montiel - A00824223
Isaac Kelly Ramirez - A00829261
Emilio marchard - A00828209
Frida Montúfar Godínez - A01652971
Daniel Quintanilla - A00825167

# Analisis de clusters jerarquicos y Kmedias

```{r, warning=FALSE, message=FALSE}
library(readxl)
library(tidyverse)
library(dplyr)
library(factoextra)

```
```{r}
D1 <- read_excel("C:/Users/tomy0/Downloads/DATOS de Situación Problema 2_Tarjetas de Crédito_UF_Minería de Datos -1.xlsx")
Datos = D1
D1 %>% head()
D1 <- rename(D1,NSE="19. NSE")
D1 <- rename(D1,c_anuales="4. COMPRAS AL AÑO.")
```

## Revisión de observaciones faltantes

```{r}
colSums(is.na(D1[,c("NSE","c_anuales")]))
```
En este caso, no hay observaciones faltantes

## Tabla de medias
```{r}
#Tabla con datos de las n=1000 observaciones
Tabla1<-D1 %>%
  summarize("n"=n(), 
            "Promedio Compras anuales" = round(mean(c_anuales),1))

#Tabla por cada Escuela
Tabla2<-D1 %>%
  group_by(NSE) %>% 
  summarize("n"=n(), 
            "Promedio de Compras anuales" = round(mean(c_anuales),1))

#Tabla agregada
Tabla <-bind_rows(Tabla2, Tabla1)
Tabla
```


Visualmente se ve que ingeniería tiene un desempeño menor al promedio, negocios un desempeño similar y los alumnos de otras escuelas un desempeño superior. Sin embargo, estas diferencias visuales hay que probar con el Análisis de varianza si son estadísticamente significativas, pero primero hay que validar los supuestos.

## Box plots

```{r}
G1 <- boxplot(c_anuales~NSE,D1)
G1
```
En el gráfico no se puede observar bien los centros de las distribuciones, porque hay observaciones extremas, las cuales se revisarán más adelante.

## Estimación del modelo

La estimación del modelo la podemos realizar con la función "aov" o con la función de "lm".

Hay que recordar que:

Ho: $\mu_I$ = $\mu_N=$ $\mu_O=$ $\mu$          (el desempeño en profesional es igual)

Ha: al menos una es diferente            (el desempeño en profesional es diferente)

```{r}
#Cambiando a factor la variable NSE
D1$NSE<-replace(D1$NSE,D1$NSE=="A/B",1)
D1$NSE<-replace(D1$NSE,D1$NSE=="C",2)
D1$NSE<-replace(D1$NSE,D1$NSE=="C-",3)
D1$NSE<-replace(D1$NSE,D1$NSE=="C+",4)

D1$Escuela<-as.factor(D1$NSE)

#Estimación ANOVA
Estimacion1 <- aov(c_anuales ~ NSE, D1)
summary(Estimacion1)

```
El nivel de significancia a utilizar será de alfa = 0.05. Debido a que alfa es mayor que el valor P de 0.00754, se concluye que se rechaza Ho a favor de Ha, al menos una media es diferente de cero.

Sin embargo, antes de proceder a comparar las medias se validará si tenemos observaciones extremas e influyentes y si se cumplan los supuestos del modelo.

## Validación de problemas en la estimación y supuestos

### Observaciones extremas influyentes

Una observación extrema respecto a la variable dependiente, es aquella que está fuera de la región experimental, esto es, esta muy por debajo o arriba de la mayoría de las observaciones. Una observación extrema influyente es aquella que cuando se quita de las estimaciones éstas se modifican drasticamente. Las observaciones extremas son tolerables pero no las influyentes.

La manera de identificar las observaciones extremas es mediante el residual estudentizado y las influyentes mediante la distancia cook.

#### Residual estudentizado

El residual estudentizado sirve para identificar observaciones extremas en la variable dependiente, se calcua por observación y si su valor obsoluto es superior a 2, la observación es extrema.

```{r}
#Calcular por observación el residual studentizado
D1$RS<-rstudent(Estimacion1)
#Identificar cuáles son las observaciones extremas
Obs_extremas<-which(abs(D1$RS) >= 2)
Obs_extremas
```
La lista de observaciones anteriores son consideradas extremas respecto a la variable dependiente.

#### Observaciones influyentes
Una observación es influyente si su distancia cook es mayor o igual a:

DCi>= F_{$\alpha$=0.5,v1=(k+1),v2=n-(k+1)}

Donde:
k= total de variables explicativas categóricas en este caso solo hay una, escuela.
n= total de observaciones
En la práctica se maneja un valor superior a 1.

```{r}
#Crear por observación la distancia cook
D1$DC<-cooks.distance(Estimacion1)
#Valor F de tablas
Fc<-qf(0.5, (1+1), (nrow(D1)-(1+1)))
#Código para identificar las observaciones extremas influyentes 
Obs_influyentes<-which(D1$DC > Fc)
Obs_influyentes
```
Mediante la distancia cook se concluye que no hay observaciones extremas influyentes.

Si bien las observaciones extremas se toleran y las influyentes no, en este análisis se optará por quitar las extremas para tener mejores conclusiones

```{r}
D2<-D1[-Obs_extremas,c("NSE","c_anuales")]
```

Las estimaciones sin observaciones extremas son:

```{r}
#Estimación ANOVA
Estimacion2 <- aov(c_anuales ~ NSE, D2)
summary(Estimacion2)
```
Se mantienen las conclusiones, las medias son estadísticamente diferentes.



## Tabla de medias
```{r}
#Tabla con datos de las n=1000 observaciones
Tabla1<-D2 %>%
  summarize("n"=n(), 
            "Promedio compras" = round(mean(c_anuales),1))

#Tabla por cada Escuela
Tabla2<-D2 %>%
  group_by(NSE) %>% 
  summarize("n"=n(), 
            "Promedio compras" = round(mean(c_anuales),1))

#Tabla agregada
Tabla <-bind_rows(Tabla2, Tabla1)
Tabla
```

Al quitar las observaciones extremas las medias se hacen más parecidas, pero aún estadísticamente son consideradas diferentes.

### Validación de supuestos
#### Muestras independientes
Este supuestos e asegura ya que en la base de datos la muestras son diferentes personas, esto es, los alumnos de ingeniería son diferentes a los de negocios y otras escuelas, esto es, son indpendientes.


#### Supuesto de normalidad
El supuesto de normalidad lo validaremos con la prueba de Jarque Bera en los residuales del ANOVA.

H0: normalidad (asimetría = 0 y curtosis = 3)
Ha: no normalidad

```{r}
library(tseries)
jarque.bera.test(resid(Estimacion2))
```
Debido que alfa=0.05 es mayor que el valor P de 0.0000000000000022, se rechaza Ho a favor de Ha, no hay normalidad.

Cuando no se cumple el supuesto de normalidad se tiene la opción de acudir al Teorema del Límite Central que dice que con muestras grandes se tiende a la normalidad, una muestra grande es arriba de 30 observaciones, en este ejemplo se tienen 947 observaciones.

Otra opción es buscar la potencia sobre la variable dependiente que asegura la normalidad, esto se puede hacer con la transformación box-cox.


Box-Cox de forma iterativa elevan la variable dependiente a una potencia y buscan la transforamción que máximiza la probabilidad de que la variable transformada tenga normalidad. En este ejercicio se le indico a Box-Cox que buscará la potencia de -100 a 100, la cual fue de 7.37.

Ya que se sabe la potencia se transforma la variable dependiente y se valida el cumplimiento del supuesto.

```{r}
#Realización de prueba de hipótesis de normalidad
library(tseries)
jarque.bera.test(resid(Estimacion2))

```
Como puede observarse aún con la transformación box-cox no se logra corregir el supuesto, entonces o se hace referencia al Teorema del Límite Central o se usa un procedimiento de prueba no paramétrico que no requiere del cumplimiento de este supuesto.

Para continuar el ejercicio se hará referencia al Teorema del Límite Central.

#### Supuesto de varianza constante

Prueba de hipótesis para identificar la varianza constante (Breusch–Pagan test)
H0: Varianza constante
Ha: Varianza no constante

```{r}
library(lmtest)
bptest(Estimacion2)
```
Como alfa de 0.05 no es mayor al valor P de 0.3491 se concluye que se cumple el supuesto de varianza constante.

## Comparación de medias

Para conocer cuál media es diferente (mayor o menor) se utilizará el procedimiento de Tukey.

```{r}
Tukey<-TukeyHSD(Estimacion2)
Tukey
```
En el primer renglón de la prueba de Tukey se hace la prueba de hipótesis de si el desempeño promedio de ingeniería es igual o diferente al del negocios, como alfa=0.05 no es mayor al valor P de 0.001, se concluye que son iguales. En el renglón 2 se compara ingeniería con el resto de las escuelas resultado una diferencia significativa de 1.58 puntos y en el rengló 3 negocios con otras escuelas donde la diferencia no es significativa.

Otra manera de verlo es con el gráfico de intervalos de confianza sobre la diferencia de las medias.

```{r}
plot(Tukey)
```

Si el intervalo incluye el cero como en el intervalo de (2-1) y (3-2) se concluye que no hay diferencia, la diferencia en las medias es igual a cero. Cómo en el intervalo de (3-1), resto escuelas menos ingeniería no incluye el cero se concluye que la diferencia de medias es diferente de cero, son diferentes.


## Procedimiento de prueba no paramétrico para comparar más de dos medias
Cuándo no se cumplen los supuestos de normalidad y de varianza constante, se pueden usar la prueba no paramétrica de Kruskal-Wallis para comparar medias e identificar si hay diferencias.

Ho: $\mu_I$ = $\mu_N=$ $\mu_O=$ $\mu$          (el desempeño en profesional es igual)

Ha: al menos una es diferente            (el desempeño en profesional es diferente)



```{r}
KT<-kruskal.test(c_anuales~NSE,D2)
KT
```
Como alfa=0.05 es mayor al valor P de 0.0006498 se rechaza Ho a favor de Ha, las medias son diferentes, el desempeño promedio de los alumnos difieren por escuela.

Para concluir qué pares de medias son diferentes se utilizará la prueba de "Conover" ajustando el error, el valor P, con el método de holm. 
      
```{r}
library(PMCMR)
posthoc.kruskal.conover.test(c_anuales~NSE,D2, p.adjust.method ="holm")
```       

Los valores que se reportan son los valores P de la comparación de pares de medias. El único valor donde alfa = 0.05 es mayor al valor P es en la comparación 1 y 3 (Ingeniería vs resto de escuelas), solo en ese para el desmepeño promedio es diferente.

Los resultados del ANOVA y de kruskal wallis salen similares.